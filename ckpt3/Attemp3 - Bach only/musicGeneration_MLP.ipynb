{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:43.948987Z",
     "start_time": "2018-11-27T12:20:30.225783Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:52.800756Z",
     "start_time": "2018-11-27T12:20:43.965495Z"
    }
   },
   "outputs": [],
   "source": [
    "from midox import midiread, midiwrite\n",
    "import pretty_midi\n",
    "import subprocess\n",
    "import taglib\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as io\n",
    "from IPython.display import FileLink, Audio\n",
    "\n",
    "from utils import NotesGenerationDataset, post_process_sequence_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'output_classic_ed.mid'\n",
    "weight_file_path = 'music_model_padfront_regularized_mlp.pth'\n",
    "\n",
    "base_dataset_path = '../midi-Data/Classical/Johann Sebastian Bach'\n",
    "\n",
    "major_notes = True\n",
    "\n",
    "train = True\n",
    "testing = True\n",
    "\n",
    "one_time_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:07.678124Z",
     "start_time": "2018-11-27T12:20:56.931002Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = NotesGenerationDataset(base_dataset_path, new_dataset=True, type='train')\n",
    "\n",
    "trainset_loader = Data.DataLoader(trainset, batch_size=1, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:08.232332Z",
     "start_time": "2018-11-27T12:21:07.693745Z"
    }
   },
   "outputs": [],
   "source": [
    "X = next(iter(trainset_loader))\n",
    "print(X[0].shape)\n",
    "\n",
    "keys_shape = X[0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.258476Z",
     "start_time": "2018-11-27T12:21:08.259258Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    valset = NotesGenerationDataset(base_dataset_path, new_dataset=True, type='val')\n",
    "\n",
    "    valset_loader = Data.DataLoader(valset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.406325Z",
     "start_time": "2018-11-27T12:21:11.278687Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    X_val = next(iter(valset_loader))\n",
    "    X_val[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valset_loader, criterion_val):\n",
    "    model.eval()\n",
    "    full_val_loss = 0.0\n",
    "    overall_sequence_length = 0.0\n",
    "    keys_shape = 88\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valset_loader):\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "            output_sequences_batch_var =  Variable(output_sequences_batch.contiguous().view(-1).to(device))\n",
    "            input_sequences_batch_var = Variable(input_sequences_batch.to(device))\n",
    "\n",
    "            if sequences_lengths[0] > one_time_size:\n",
    "                for i in range(sequences_lengths[0] - one_time_size - 1):\n",
    "                    last_100_notes = input_sequences_batch_var[i:i+one_time_size, :, :]\n",
    "\n",
    "                    out = model(last_100_notes)#.reshape(input_sequences_batch_var.shape[1], -1)\n",
    "\n",
    "                    loss = criterion_val(out, input_sequences_batch_var[i+one_time_size].flatten())\n",
    "\n",
    "                    full_val_loss += loss.item()\n",
    "                    overall_sequence_length += sum(sequences_lengths)\n",
    "            keys_shape = input_sequences_batch.shape[2]\n",
    "    \n",
    "    return full_val_loss / (overall_sequence_length * keys_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lrs_triangular, trainset_loader, criterion, valset_loader, criterion_val, epochs_number=2, wd=0.0, best_val_loss=float(\"inf\"), clip=1.0, save=True, save_path = 'music_model_padfront_regularized.pth'):\n",
    "    loss_list = []\n",
    "    val_list =[]\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n",
    "    for epoch_number in range(epochs_number):\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        print(\"Epoch: \", epoch_number)\n",
    "        for lr, batch in tqdm(zip(lrs_triangular, trainset_loader)):\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "            output_sequences_batch_var =  Variable(output_sequences_batch.contiguous().view(-1).to(device))\n",
    "            input_sequences_batch_var = Variable(input_sequences_batch.to(device))\n",
    "\n",
    "            if sequences_lengths[0] > one_time_size:\n",
    "                for i in range(sequences_lengths[0] - one_time_size-1):\n",
    "                    optimizer.zero_grad()\n",
    "                    last_100_notes = input_sequences_batch_var[i:i+one_time_size, :, :]\n",
    "\n",
    "                    out = model(last_100_notes)\n",
    "\n",
    "                    loss = criterion(out, input_sequences_batch_var[i+one_time_size].flatten())\n",
    "\n",
    "                    loss_list.append(loss.item())\n",
    "                    epoch_loss.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                    optimizer.step()\n",
    "\n",
    "        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
    "        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
    "\n",
    "        current_val_loss = validate(model, valset_loader, criterion_val)\n",
    "        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
    "        print('')\n",
    "\n",
    "        val_list.append(current_val_loss)\n",
    "\n",
    "        if current_val_loss < best_val_loss:\n",
    "            if save:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "            best_val_loss = current_val_loss\n",
    "    \n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testset_loader):\n",
    "    model.eval()\n",
    "    accuracies = []\n",
    "    l = len(testset_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(testset_loader):\n",
    "            print(i+1, \"/\", l)\n",
    "            acc = []\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "            input_sequences_batch_var = Variable(input_sequences_batch.to(device))\n",
    "\n",
    "            non_zero_indices = np.argwhere(input_sequences_batch_var.cpu().numpy() > 0)[:, 0]\n",
    "\n",
    "            for index in tqdm(np.unique(non_zero_indices)):\n",
    "                if index >= sequences_lengths[0] - 1:\n",
    "                    break\n",
    "                if index > sequences_lengths[0] - one_time_size:\n",
    "                    break\n",
    "                out = model(input_sequences_batch_var[index:index+one_time_size].view(one_time_size, 1, 128))\n",
    "                probabilities = nn.functional.softmax(out, dim=1)\n",
    "                output = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "                output = Variable(output.float())\n",
    "\n",
    "                a = input_sequences_batch_var.cpu().numpy()[1+index][0]\n",
    "                b = output.squeeze(1).cpu().numpy()[0]\n",
    "\n",
    "                distance = np.sum(a!=b)\n",
    "                length = len(a)\n",
    "                accuracy = 1 - (distance / length)\n",
    "                acc.append(accuracy)\n",
    "\n",
    "            accuracies.append(np.mean(accuracy))\n",
    "    \n",
    "    print(np.mean(accuracies))\n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:33.314323Z",
     "start_time": "2018-11-27T12:22:33.291386Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.flatten()\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:57.954631Z",
     "start_time": "2018-11-27T12:22:36.786295Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MLP(input_size=keys_shape*one_time_size, hidden_size=512, num_classes=keys_shape).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "criterion_val = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:23:12.210378Z",
     "start_time": "2018-11-27T12:22:58.040622Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    validate(model, valset_loader, criterion_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:23:12.255258Z",
     "start_time": "2018-11-27T12:23:12.244288Z"
    }
   },
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "epochs_number = 10\n",
    "sample_history = []\n",
    "best_val_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:23:18.442825Z",
     "start_time": "2018-11-27T12:23:18.430860Z"
    }
   },
   "outputs": [],
   "source": [
    "def lrfinder(start, end, model, trainset_loader, epochs=2):\n",
    "    model.train() # into training mode\n",
    "    lrs = np.linspace(start, end, epochs*len(trainset_loader))\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(model.parameters(),start)\n",
    "    loss_list = []\n",
    "    ctr = 0\n",
    "    \n",
    "    for epoch_number in range(epochs):\n",
    "        epoch_loss = []\n",
    "        print('Epoch %d' % epoch_number)\n",
    "        for batch in tqdm(trainset_loader):\n",
    "            optimizer.param_groups[0]['lr'] = lrs[ctr]\n",
    "            ctr = ctr+1\n",
    "\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).to(device) )\n",
    "            input_sequences_batch_var = Variable( input_sequences_batch.to(device) )\n",
    "\n",
    "            if sequences_lengths[0] > one_time_size:\n",
    "                for i in range(sequences_lengths[0] - one_time_size-1):\n",
    "                    last_100_notes = input_sequences_batch_var[i:i+one_time_size, :, :]\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model(last_100_notes)\n",
    "\n",
    "                    loss = criterion(logits, input_sequences_batch_var[i+one_time_size].flatten())\n",
    "\n",
    "                    epoch_loss.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss.append(loss.item())\n",
    "        \n",
    "        print('Loss %.4f' % np.mean(epoch_loss))\n",
    "        # plt.plot(range(len(trainset_loader)), epoch_loss)\n",
    "        # plt.show()\n",
    "    plt.plot(lrs, loss_list)\n",
    "    return lrs, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:13:45.182544Z",
     "start_time": "2018-11-26T16:11:13.582351Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    rnn = MLP(input_size=keys_shape*one_time_size, hidden_size=512, num_classes=keys_shape).to(device)\n",
    "    lrs, losses = lrfinder(1e-5, 5e-4, rnn, trainset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:14.159868Z",
     "start_time": "2018-11-26T16:16:13.950619Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    plt.plot(lrs[:15], losses[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:15.631943Z",
     "start_time": "2018-11-26T16:16:15.434830Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    def get_triangular_lr(lr_low, lr_high, mini_batches):\n",
    "        iterations = mini_batches\n",
    "        lr_mid = lr_high/7 + lr_low\n",
    "        up = np.linspace(lr_low, lr_high, int(round(iterations*0.35)))\n",
    "        down = np.linspace(lr_high, lr_mid, int(round(iterations*0.35)))\n",
    "        floor = np.linspace(lr_mid, lr_low, int(round(iterations*0.30)))\n",
    "        return np.hstack([up, down[1:], floor])\n",
    "\n",
    "    lrs_triangular = get_triangular_lr(1e-5, 1e-3, len(trainset_loader))\n",
    "    plt.plot(lrs_triangular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:19:05.465667Z",
     "start_time": "2018-11-26T16:16:20.312589Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    mlp = MLP(input_size=keys_shape*one_time_size, hidden_size=512, num_classes=keys_shape).to(device)\n",
    "    lrs_triangular = get_triangular_lr(1e-5, 1e-4, len(trainset_loader))\n",
    "    best_val_loss = train_model(mlp, lrs_triangular, trainset_loader, criterion, valset_loader, criterion_val, save_path=weight_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:21:52.147229Z",
     "start_time": "2018-11-26T16:19:05.617260Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    lrs_triangular = get_triangular_lr(1e-6, 1e-4, len(trainset_loader))\n",
    "    best_val_loss = train_model(mlp, lrs_triangular, trainset_loader, criterion, valset_loader, criterion_val, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss, save_path=weight_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:24:39.239756Z",
     "start_time": "2018-11-26T16:21:52.289423Z"
    }
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    lrs_triangular = get_triangular_lr(1e-5, 1e-4, len(trainset_loader))\n",
    "    best_val_loss = train_model(mlp, lrs_triangular, trainset_loader, criterion, valset_loader, criterion_val, epochs_number=2, wd=1e-4*5, best_val_loss=best_val_loss, save_path=weight_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:15:52.123518Z",
     "start_time": "2018-11-26T16:11:03.940Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MLP(input_size=keys_shape*one_time_size, hidden_size=512, num_classes=keys_shape).to(device)\n",
    "mlp.load_state_dict(torch.load(weight_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:11.202962Z",
     "start_time": "2018-11-26T16:25:11.189993Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_from_piano_rnn(model, sample_length=4, temperature=1, starting_sequence=None):\n",
    "    if starting_sequence is None:\n",
    "        current_sequence_input = torch.zeros(1, 1, keys_shape)\n",
    "        current_sequence_input[0, 0, 40] = 1\n",
    "        current_sequence_input[0, 0, 50] = 0\n",
    "        current_sequence_input[0, 0, 56] = 0\n",
    "        current_sequence_input = Variable(current_sequence_input.to(device))\n",
    "    else:\n",
    "        current_sequence_input = starting_sequence\n",
    "        \n",
    "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    prev = 0\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < (sample_length + 10):\n",
    "        output, hidden = model(current_sequence_input, [1], hidden)\n",
    "\n",
    "        probabilities = nn.functional.softmax(output.divide(temperature), dim=1)\n",
    "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "        current_sequence_input = Variable(current_sequence_input.float())\n",
    "\n",
    "        if not current_sequence_input.data.squeeze(1).cpu().numpy()[0].any():\n",
    "            prev +=1\n",
    "        else:\n",
    "            prev = 0\n",
    "        \n",
    "        if prev >= 4:\n",
    "            continue\n",
    "\n",
    "        i+=1\n",
    "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
    "\n",
    "    sampled_sequence = torch.cat(final_output_sequence[10:], dim=0).cpu().numpy()\n",
    "    \n",
    "    return sampled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:16.419484Z",
     "start_time": "2018-11-26T16:25:14.709507Z"
    }
   },
   "outputs": [],
   "source": [
    "testset =  NotesGenerationDataset(base_dataset_path, new_dataset=True, type='test')\n",
    "\n",
    "testset_loader = Data.DataLoader(testset, batch_size=1,shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:18.156725Z",
     "start_time": "2018-11-26T16:25:17.906750Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(testset_loader))\n",
    "batch = next(iter(testset_loader))\n",
    "post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).to(device)\n",
    "\n",
    "input_sequences_batch_var = input_sequences_batch.to(device)\n",
    "input_sequences_batch_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    test(mlp, testset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:33.195424Z",
     "start_time": "2018-11-26T16:25:32.923613Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(input_sequences_batch_var.cpu().numpy().reshape((input_sequences_batch_var.shape[0],keys_shape)).transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:36.632928Z",
     "start_time": "2018-11-26T16:25:34.966547Z"
    }
   },
   "outputs": [],
   "source": [
    "piano_roll = sample_from_piano_rnn(mlp, sample_length=400, temperature=0.95, starting_sequence=input_sequences_batch_var[0].view(1,1,-1))\n",
    "io.imshow(piano_roll.transpose())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midiwrite(output_file_name, piano_roll, dt=0.15, r=(0, 109))\n",
    "\n",
    "# from pypianoroll import Multitrack, BinaryTrack\n",
    "# piano_roll[:, 89:] = 0\n",
    "# track_name = 'Piano'\n",
    "# pianoroll_track = BinaryTrack(pianoroll=piano_roll, name=track_name)\n",
    "# multitrack_name = 'MyMultitrack'  # Set a name for the multitrack\n",
    "# multitrack = Multitrack(tracks=[pianoroll_track], name=multitrack_name, resolution=1)\n",
    "# print(multitrack)\n",
    "# multitrack.write('output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_major_note(note):\n",
    "    # Check if the note is a major note (C, D, E, F, G, A, B)\n",
    "    major_notes = [0, 2, 4, 5, 7, 9, 11]\n",
    "    return note % 12 in major_notes\n",
    "    # return True\n",
    "\n",
    "def filter_major_notes(input_file, output_file):\n",
    "    midi_data = pretty_midi.PrettyMIDI(input_file)\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        # Keep only major notes in the instrument\n",
    "        instrument.notes = [note for note in instrument.notes if is_major_note(note.pitch)]\n",
    "\n",
    "    # Save the modified MIDI data to a new file\n",
    "    midi_data.write(output_file)\n",
    "\n",
    "if major_notes:\n",
    "    filter_major_notes(output_file_name, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:30:38.850609Z",
     "start_time": "2018-11-26T16:30:38.843627Z"
    }
   },
   "outputs": [],
   "source": [
    "FileLink(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['fluidsynth', '-ni', '-g', '1', '../IK_Berlin_Grand_Piano.sf2', output_file_name, '-F', \".\".join(output_file_name.split('.')[:-1]) + '.wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with taglib.File(\".\".join(output_file_name.split('.')[:-1]) + '.wav', save_on_exit=True) as song:\n",
    "    song.tags[\"ALBUM\"] = [\"Music Generation\"]\n",
    "    song.tags[\"ARTIST\"] = [\"LSTM\"]\n",
    "    song.tags[\"TITLE\"] = [\"Generated Music\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\".\".join(output_file_name.split('.')[:-1]) + '.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
