{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 500\n",
    "num_classes = 4\n",
    "alpha = 0.0001\n",
    "num_epochs = 200\n",
    "batch_size = 512\n",
    "hidden_layer = 128\n",
    "classification_weight = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(label_num, num_classes=4):\n",
    "    one_hot = np.zeros((1, num_classes))\n",
    "    one_hot[0, int(label_num)] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print('Reading data...')\n",
    "    songs = []\n",
    "    onehotlabels = []\n",
    "\n",
    "    all_genres = ['Classical', 'Jazz', 'Pop']\n",
    "\n",
    "    numsplit = 20\n",
    "    sizesplit = input_dim\n",
    "\n",
    "    for index in range(len(all_genres)):\n",
    "        for foldername, subfolders, filenames in tqdm(os.walk('../wav-Data/' + all_genres[index])):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    try:\n",
    "                        audio, _ = librosa.load(os.path.join(foldername, filename))\n",
    "                    except Exception as e:\n",
    "                        print(f'Error encountered: {e}')\n",
    "                        continue\n",
    "\n",
    "                    audio = audio[:600000]\n",
    "                    if len(audio) % 40 != 0:\n",
    "                        audio = np.pad(audio, (0, 40 - len(audio) % 40), 'constant', constant_values=np.mean(audio[-(40 - len(audio) % 40):]))\n",
    "                    audio = audio.reshape(-1, 40)\n",
    "                    audio = np.mean(audio, axis=1)\n",
    "\n",
    "                    for j in range(numsplit):\n",
    "                        start_index = sizesplit * j\n",
    "                        if start_index >= len(audio):\n",
    "                            break\n",
    "                        end_index = sizesplit * (j + 1)\n",
    "                        if end_index >= len(audio):\n",
    "                            end_index = len(audio)-1\n",
    "                        songs.append(audio[start_index:end_index])\n",
    "                        onehotlabels.append(get_one_hot(index)[0])\n",
    "\n",
    "    songs = pd.DataFrame(songs)\n",
    "    onehotlabels = pd.DataFrame(onehotlabels)\n",
    "    print('Data reading done :)')\n",
    "    return songs, onehotlabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:34,  6.91s/it]\n",
      "2it [00:16,  8.43s/it]\n",
      "2it [00:22, 11.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reading done :)\n"
     ]
    }
   ],
   "source": [
    "songs, labels = load_data()\n",
    "\n",
    "# Shuffling training set\n",
    "ind_list = [i for i in range(songs.shape[0])]\n",
    "shuffle(ind_list)\n",
    "songs = songs.iloc[ind_list]\n",
    "labels = labels.iloc[ind_list]\n",
    "\n",
    "songs_train = songs.iloc[0:6000].values\n",
    "songs_dev = songs.iloc[6000:].values\n",
    "labels_train = labels.iloc[0:6000].values\n",
    "labels_dev = labels.iloc[6000:].values\n",
    "\n",
    "train_dataset = data.TensorDataset(torch.from_numpy(songs_train).float(), torch.from_numpy(labels_train).long())\n",
    "dev_dataset = data.TensorDataset(torch.from_numpy(songs_dev).float(), torch.from_numpy(labels_dev).long())\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = data.DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, hidden=128):\n",
    "        super(SoftmaxClassifier, self).__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_softmax(model, train_loader, dev_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_accuracies = []\n",
    "    dev_accuracies = []\n",
    "    loss_per_epoch = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct_train = 0\n",
    "\n",
    "        for inputs_batch, labels_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_batch)\n",
    "            loss = criterion(outputs, labels_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels_batch = torch.max(labels_batch.data, 1)\n",
    "            correct_train += (predicted == labels_batch).sum().item()\n",
    "\n",
    "        accuracy_train = correct_train / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}, Train Accuracy: {accuracy_train}\")\n",
    "\n",
    "        model.eval()\n",
    "        correct_dev = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs_batch, labels_batch in dev_loader:\n",
    "                outputs = model(inputs_batch)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                _, labels_batch = torch.max(labels_batch.data, 1)\n",
    "                correct_dev += (predicted == labels_batch).sum().item()\n",
    "\n",
    "        accuracy_dev = correct_dev / len(dev_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}, Dev Accuracy: {accuracy_dev}\")\n",
    "\n",
    "        train_accuracies.append(accuracy_train)\n",
    "        dev_accuracies.append(accuracy_dev)\n",
    "        loss_per_epoch.append(total_loss / len(train_loader))\n",
    "\n",
    "    return train_accuracies, dev_accuracies, loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 0.20166666666666666\n",
      "Epoch 1, Dev Accuracy: 0.21911357340720222\n",
      "Epoch 2, Train Accuracy: 0.23166666666666666\n",
      "Epoch 2, Dev Accuracy: 0.24875346260387812\n",
      "Epoch 3, Train Accuracy: 0.2795\n",
      "Epoch 3, Dev Accuracy: 0.30498614958448755\n",
      "Epoch 4, Train Accuracy: 0.3625\n",
      "Epoch 4, Dev Accuracy: 0.39002770083102495\n",
      "Epoch 5, Train Accuracy: 0.4325\n",
      "Epoch 5, Dev Accuracy: 0.40969529085872575\n",
      "Epoch 6, Train Accuracy: 0.4675\n",
      "Epoch 6, Dev Accuracy: 0.47257617728531853\n",
      "Epoch 7, Train Accuracy: 0.517\n",
      "Epoch 7, Dev Accuracy: 0.5058171745152354\n",
      "Epoch 8, Train Accuracy: 0.5401666666666667\n",
      "Epoch 8, Dev Accuracy: 0.528393351800554\n",
      "Epoch 9, Train Accuracy: 0.5583333333333333\n",
      "Epoch 9, Dev Accuracy: 0.5412742382271468\n",
      "Epoch 10, Train Accuracy: 0.569\n",
      "Epoch 10, Dev Accuracy: 0.5476454293628809\n",
      "Epoch 11, Train Accuracy: 0.5746666666666667\n",
      "Epoch 11, Dev Accuracy: 0.5527700831024931\n",
      "Epoch 12, Train Accuracy: 0.5796666666666667\n",
      "Epoch 12, Dev Accuracy: 0.5558171745152355\n",
      "Epoch 13, Train Accuracy: 0.5828333333333333\n",
      "Epoch 13, Dev Accuracy: 0.5585872576177285\n",
      "Epoch 14, Train Accuracy: 0.5841666666666666\n",
      "Epoch 14, Dev Accuracy: 0.5621883656509695\n",
      "Epoch 15, Train Accuracy: 0.5868333333333333\n",
      "Epoch 15, Dev Accuracy: 0.564819944598338\n",
      "Epoch 16, Train Accuracy: 0.5886666666666667\n",
      "Epoch 16, Dev Accuracy: 0.567174515235457\n",
      "Epoch 17, Train Accuracy: 0.591\n",
      "Epoch 17, Dev Accuracy: 0.5691135734072023\n",
      "Epoch 18, Train Accuracy: 0.5921666666666666\n",
      "Epoch 18, Dev Accuracy: 0.5709141274238227\n",
      "Epoch 19, Train Accuracy: 0.592\n",
      "Epoch 19, Dev Accuracy: 0.5714681440443213\n",
      "Epoch 20, Train Accuracy: 0.5936666666666667\n",
      "Epoch 20, Dev Accuracy: 0.5734072022160664\n",
      "Epoch 21, Train Accuracy: 0.5941666666666666\n",
      "Epoch 21, Dev Accuracy: 0.5749307479224377\n",
      "Epoch 22, Train Accuracy: 0.5955\n",
      "Epoch 22, Dev Accuracy: 0.5761772853185596\n",
      "Epoch 23, Train Accuracy: 0.5961666666666666\n",
      "Epoch 23, Dev Accuracy: 0.5765927977839335\n",
      "Epoch 24, Train Accuracy: 0.5978333333333333\n",
      "Epoch 24, Dev Accuracy: 0.5772853185595568\n",
      "Epoch 25, Train Accuracy: 0.5995\n",
      "Epoch 25, Dev Accuracy: 0.5786703601108033\n",
      "Epoch 26, Train Accuracy: 0.6001666666666666\n",
      "Epoch 26, Dev Accuracy: 0.5795013850415512\n",
      "Epoch 27, Train Accuracy: 0.601\n",
      "Epoch 27, Dev Accuracy: 0.5818559556786703\n",
      "Epoch 28, Train Accuracy: 0.6001666666666666\n",
      "Epoch 28, Dev Accuracy: 0.5821329639889197\n",
      "Epoch 29, Train Accuracy: 0.6003333333333334\n",
      "Epoch 29, Dev Accuracy: 0.5835180055401662\n",
      "Epoch 30, Train Accuracy: 0.6005\n",
      "Epoch 30, Dev Accuracy: 0.5832409972299168\n",
      "Epoch 31, Train Accuracy: 0.6013333333333334\n",
      "Epoch 31, Dev Accuracy: 0.5835180055401662\n",
      "Epoch 32, Train Accuracy: 0.602\n",
      "Epoch 32, Dev Accuracy: 0.5833795013850416\n",
      "Epoch 33, Train Accuracy: 0.6026666666666667\n",
      "Epoch 33, Dev Accuracy: 0.5837950138504155\n",
      "Epoch 34, Train Accuracy: 0.603\n",
      "Epoch 34, Dev Accuracy: 0.5854570637119113\n",
      "Epoch 35, Train Accuracy: 0.603\n",
      "Epoch 35, Dev Accuracy: 0.586426592797784\n",
      "Epoch 36, Train Accuracy: 0.6033333333333334\n",
      "Epoch 36, Dev Accuracy: 0.5865650969529086\n",
      "Epoch 37, Train Accuracy: 0.6033333333333334\n",
      "Epoch 37, Dev Accuracy: 0.5868421052631579\n",
      "Epoch 38, Train Accuracy: 0.6035\n",
      "Epoch 38, Dev Accuracy: 0.5871191135734072\n",
      "Epoch 39, Train Accuracy: 0.6036666666666667\n",
      "Epoch 39, Dev Accuracy: 0.5875346260387811\n",
      "Epoch 40, Train Accuracy: 0.6036666666666667\n",
      "Epoch 40, Dev Accuracy: 0.5882271468144045\n",
      "Epoch 41, Train Accuracy: 0.6045\n",
      "Epoch 41, Dev Accuracy: 0.5889196675900277\n",
      "Epoch 42, Train Accuracy: 0.6045\n",
      "Epoch 42, Dev Accuracy: 0.5889196675900277\n",
      "Epoch 43, Train Accuracy: 0.6048333333333333\n",
      "Epoch 43, Dev Accuracy: 0.5889196675900277\n",
      "Epoch 44, Train Accuracy: 0.6051666666666666\n",
      "Epoch 44, Dev Accuracy: 0.589196675900277\n",
      "Epoch 45, Train Accuracy: 0.6051666666666666\n",
      "Epoch 45, Dev Accuracy: 0.5890581717451524\n",
      "Epoch 46, Train Accuracy: 0.6053333333333333\n",
      "Epoch 46, Dev Accuracy: 0.589196675900277\n",
      "Epoch 47, Train Accuracy: 0.605\n",
      "Epoch 47, Dev Accuracy: 0.5893351800554016\n",
      "Epoch 48, Train Accuracy: 0.6053333333333333\n",
      "Epoch 48, Dev Accuracy: 0.5894736842105263\n",
      "Epoch 49, Train Accuracy: 0.6058333333333333\n",
      "Epoch 49, Dev Accuracy: 0.589612188365651\n",
      "Epoch 50, Train Accuracy: 0.6061666666666666\n",
      "Epoch 50, Dev Accuracy: 0.5893351800554016\n",
      "Epoch 51, Train Accuracy: 0.6061666666666666\n",
      "Epoch 51, Dev Accuracy: 0.589612188365651\n",
      "Epoch 52, Train Accuracy: 0.606\n",
      "Epoch 52, Dev Accuracy: 0.5897506925207756\n",
      "Epoch 53, Train Accuracy: 0.6061666666666666\n",
      "Epoch 53, Dev Accuracy: 0.589612188365651\n",
      "Epoch 54, Train Accuracy: 0.6063333333333333\n",
      "Epoch 54, Dev Accuracy: 0.5898891966759002\n",
      "Epoch 55, Train Accuracy: 0.6058333333333333\n",
      "Epoch 55, Dev Accuracy: 0.590027700831025\n",
      "Epoch 56, Train Accuracy: 0.6058333333333333\n",
      "Epoch 56, Dev Accuracy: 0.5903047091412742\n",
      "Epoch 57, Train Accuracy: 0.6058333333333333\n",
      "Epoch 57, Dev Accuracy: 0.5903047091412742\n",
      "Epoch 58, Train Accuracy: 0.6063333333333333\n",
      "Epoch 58, Dev Accuracy: 0.5898891966759002\n",
      "Epoch 59, Train Accuracy: 0.6063333333333333\n",
      "Epoch 59, Dev Accuracy: 0.590027700831025\n",
      "Epoch 60, Train Accuracy: 0.6063333333333333\n",
      "Epoch 60, Dev Accuracy: 0.589612188365651\n",
      "Epoch 61, Train Accuracy: 0.6066666666666667\n",
      "Epoch 61, Dev Accuracy: 0.589612188365651\n",
      "Epoch 62, Train Accuracy: 0.6068333333333333\n",
      "Epoch 62, Dev Accuracy: 0.5894736842105263\n",
      "Epoch 63, Train Accuracy: 0.6068333333333333\n",
      "Epoch 63, Dev Accuracy: 0.5894736842105263\n",
      "Epoch 64, Train Accuracy: 0.607\n",
      "Epoch 64, Dev Accuracy: 0.5897506925207756\n",
      "Epoch 65, Train Accuracy: 0.607\n",
      "Epoch 65, Dev Accuracy: 0.589612188365651\n",
      "Epoch 66, Train Accuracy: 0.6066666666666667\n",
      "Epoch 66, Dev Accuracy: 0.589612188365651\n",
      "Epoch 67, Train Accuracy: 0.6066666666666667\n",
      "Epoch 67, Dev Accuracy: 0.5893351800554016\n",
      "Epoch 68, Train Accuracy: 0.6066666666666667\n",
      "Epoch 68, Dev Accuracy: 0.589196675900277\n",
      "Epoch 69, Train Accuracy: 0.6066666666666667\n",
      "Epoch 69, Dev Accuracy: 0.589196675900277\n",
      "Epoch 70, Train Accuracy: 0.6068333333333333\n",
      "Epoch 70, Dev Accuracy: 0.5893351800554016\n",
      "Epoch 71, Train Accuracy: 0.6068333333333333\n",
      "Epoch 71, Dev Accuracy: 0.589196675900277\n",
      "Epoch 72, Train Accuracy: 0.607\n",
      "Epoch 72, Dev Accuracy: 0.5890581717451524\n",
      "Epoch 73, Train Accuracy: 0.6073333333333333\n",
      "Epoch 73, Dev Accuracy: 0.5886426592797784\n",
      "Epoch 74, Train Accuracy: 0.6076666666666667\n",
      "Epoch 74, Dev Accuracy: 0.5885041551246537\n",
      "Epoch 75, Train Accuracy: 0.6075\n",
      "Epoch 75, Dev Accuracy: 0.5886426592797784\n",
      "Epoch 76, Train Accuracy: 0.6076666666666667\n",
      "Epoch 76, Dev Accuracy: 0.5885041551246537\n",
      "Epoch 77, Train Accuracy: 0.6078333333333333\n",
      "Epoch 77, Dev Accuracy: 0.5882271468144045\n",
      "Epoch 78, Train Accuracy: 0.6076666666666667\n",
      "Epoch 78, Dev Accuracy: 0.5879501385041551\n",
      "Epoch 79, Train Accuracy: 0.6078333333333333\n",
      "Epoch 79, Dev Accuracy: 0.5878116343490305\n",
      "Epoch 80, Train Accuracy: 0.6078333333333333\n",
      "Epoch 80, Dev Accuracy: 0.5876731301939058\n",
      "Epoch 81, Train Accuracy: 0.6076666666666667\n",
      "Epoch 81, Dev Accuracy: 0.5876731301939058\n",
      "Epoch 82, Train Accuracy: 0.6076666666666667\n",
      "Epoch 82, Dev Accuracy: 0.5876731301939058\n",
      "Epoch 83, Train Accuracy: 0.6078333333333333\n",
      "Epoch 83, Dev Accuracy: 0.5872576177285319\n",
      "Epoch 84, Train Accuracy: 0.6086666666666667\n",
      "Epoch 84, Dev Accuracy: 0.5875346260387811\n",
      "Epoch 85, Train Accuracy: 0.6088333333333333\n",
      "Epoch 85, Dev Accuracy: 0.5871191135734072\n",
      "Epoch 86, Train Accuracy: 0.6086666666666667\n",
      "Epoch 86, Dev Accuracy: 0.5869806094182826\n",
      "Epoch 87, Train Accuracy: 0.6085\n",
      "Epoch 87, Dev Accuracy: 0.5869806094182826\n",
      "Epoch 88, Train Accuracy: 0.6086666666666667\n",
      "Epoch 88, Dev Accuracy: 0.5867036011080332\n",
      "Epoch 89, Train Accuracy: 0.6085\n",
      "Epoch 89, Dev Accuracy: 0.5861495844875346\n",
      "Epoch 90, Train Accuracy: 0.6083333333333333\n",
      "Epoch 90, Dev Accuracy: 0.5861495844875346\n",
      "Epoch 91, Train Accuracy: 0.6083333333333333\n",
      "Epoch 91, Dev Accuracy: 0.58601108033241\n",
      "Epoch 92, Train Accuracy: 0.6083333333333333\n",
      "Epoch 92, Dev Accuracy: 0.58601108033241\n",
      "Epoch 93, Train Accuracy: 0.6085\n",
      "Epoch 93, Dev Accuracy: 0.5858725761772853\n",
      "Epoch 94, Train Accuracy: 0.6081666666666666\n",
      "Epoch 94, Dev Accuracy: 0.58601108033241\n",
      "Epoch 95, Train Accuracy: 0.6086666666666667\n",
      "Epoch 95, Dev Accuracy: 0.5857340720221607\n",
      "Epoch 96, Train Accuracy: 0.6085\n",
      "Epoch 96, Dev Accuracy: 0.5854570637119113\n",
      "Epoch 97, Train Accuracy: 0.6081666666666666\n",
      "Epoch 97, Dev Accuracy: 0.585595567867036\n",
      "Epoch 98, Train Accuracy: 0.6081666666666666\n",
      "Epoch 98, Dev Accuracy: 0.5854570637119113\n",
      "Epoch 99, Train Accuracy: 0.6078333333333333\n",
      "Epoch 99, Dev Accuracy: 0.5853185595567867\n",
      "Epoch 100, Train Accuracy: 0.6081666666666666\n",
      "Epoch 100, Dev Accuracy: 0.5854570637119113\n",
      "Epoch 101, Train Accuracy: 0.6081666666666666\n",
      "Epoch 101, Dev Accuracy: 0.5853185595567867\n",
      "Epoch 102, Train Accuracy: 0.608\n",
      "Epoch 102, Dev Accuracy: 0.585595567867036\n",
      "Epoch 103, Train Accuracy: 0.608\n",
      "Epoch 103, Dev Accuracy: 0.585595567867036\n",
      "Epoch 104, Train Accuracy: 0.6083333333333333\n",
      "Epoch 104, Dev Accuracy: 0.5854570637119113\n",
      "Epoch 105, Train Accuracy: 0.6086666666666667\n",
      "Epoch 105, Dev Accuracy: 0.5854570637119113\n",
      "Epoch 106, Train Accuracy: 0.6086666666666667\n",
      "Epoch 106, Dev Accuracy: 0.5851800554016621\n",
      "Epoch 107, Train Accuracy: 0.6088333333333333\n",
      "Epoch 107, Dev Accuracy: 0.5853185595567867\n",
      "Epoch 108, Train Accuracy: 0.609\n",
      "Epoch 108, Dev Accuracy: 0.5849030470914127\n",
      "Epoch 109, Train Accuracy: 0.6095\n",
      "Epoch 109, Dev Accuracy: 0.5849030470914127\n",
      "Epoch 110, Train Accuracy: 0.61\n",
      "Epoch 110, Dev Accuracy: 0.5846260387811635\n",
      "Epoch 111, Train Accuracy: 0.6098333333333333\n",
      "Epoch 111, Dev Accuracy: 0.5844875346260388\n",
      "Epoch 112, Train Accuracy: 0.6101666666666666\n",
      "Epoch 112, Dev Accuracy: 0.5843490304709141\n",
      "Epoch 113, Train Accuracy: 0.6101666666666666\n",
      "Epoch 113, Dev Accuracy: 0.5842105263157895\n",
      "Epoch 114, Train Accuracy: 0.6098333333333333\n",
      "Epoch 114, Dev Accuracy: 0.5842105263157895\n",
      "Epoch 115, Train Accuracy: 0.61\n",
      "Epoch 115, Dev Accuracy: 0.5840720221606648\n",
      "Epoch 116, Train Accuracy: 0.6098333333333333\n",
      "Epoch 116, Dev Accuracy: 0.5839335180055402\n",
      "Epoch 117, Train Accuracy: 0.61\n",
      "Epoch 117, Dev Accuracy: 0.5839335180055402\n",
      "Epoch 118, Train Accuracy: 0.61\n",
      "Epoch 118, Dev Accuracy: 0.5842105263157895\n",
      "Epoch 119, Train Accuracy: 0.6098333333333333\n",
      "Epoch 119, Dev Accuracy: 0.5836565096952908\n",
      "Epoch 120, Train Accuracy: 0.6098333333333333\n",
      "Epoch 120, Dev Accuracy: 0.5837950138504155\n",
      "Epoch 121, Train Accuracy: 0.6098333333333333\n",
      "Epoch 121, Dev Accuracy: 0.5836565096952908\n",
      "Epoch 122, Train Accuracy: 0.6101666666666666\n",
      "Epoch 122, Dev Accuracy: 0.582825484764543\n",
      "Epoch 123, Train Accuracy: 0.61\n",
      "Epoch 123, Dev Accuracy: 0.5829639889196676\n",
      "Epoch 124, Train Accuracy: 0.6095\n",
      "Epoch 124, Dev Accuracy: 0.5829639889196676\n",
      "Epoch 125, Train Accuracy: 0.6103333333333333\n",
      "Epoch 125, Dev Accuracy: 0.582825484764543\n",
      "Epoch 126, Train Accuracy: 0.6105\n",
      "Epoch 126, Dev Accuracy: 0.5825484764542936\n",
      "Epoch 127, Train Accuracy: 0.6106666666666667\n",
      "Epoch 127, Dev Accuracy: 0.581994459833795\n",
      "Epoch 128, Train Accuracy: 0.6106666666666667\n",
      "Epoch 128, Dev Accuracy: 0.5821329639889197\n",
      "Epoch 129, Train Accuracy: 0.6103333333333333\n",
      "Epoch 129, Dev Accuracy: 0.582409972299169\n",
      "Epoch 130, Train Accuracy: 0.6105\n",
      "Epoch 130, Dev Accuracy: 0.581994459833795\n",
      "Epoch 131, Train Accuracy: 0.6105\n",
      "Epoch 131, Dev Accuracy: 0.5821329639889197\n",
      "Epoch 132, Train Accuracy: 0.6105\n",
      "Epoch 132, Dev Accuracy: 0.5815789473684211\n",
      "Epoch 133, Train Accuracy: 0.6105\n",
      "Epoch 133, Dev Accuracy: 0.5815789473684211\n",
      "Epoch 134, Train Accuracy: 0.6105\n",
      "Epoch 134, Dev Accuracy: 0.5818559556786703\n",
      "Epoch 135, Train Accuracy: 0.6105\n",
      "Epoch 135, Dev Accuracy: 0.5813019390581717\n",
      "Epoch 136, Train Accuracy: 0.6106666666666667\n",
      "Epoch 136, Dev Accuracy: 0.5815789473684211\n",
      "Epoch 137, Train Accuracy: 0.6103333333333333\n",
      "Epoch 137, Dev Accuracy: 0.5813019390581717\n",
      "Epoch 138, Train Accuracy: 0.6103333333333333\n",
      "Epoch 138, Dev Accuracy: 0.5817174515235457\n",
      "Epoch 139, Train Accuracy: 0.6098333333333333\n",
      "Epoch 139, Dev Accuracy: 0.5808864265927978\n",
      "Epoch 140, Train Accuracy: 0.61\n",
      "Epoch 140, Dev Accuracy: 0.5806094182825485\n",
      "Epoch 141, Train Accuracy: 0.6101666666666666\n",
      "Epoch 141, Dev Accuracy: 0.5795013850415512\n",
      "Epoch 142, Train Accuracy: 0.6101666666666666\n",
      "Epoch 142, Dev Accuracy: 0.5795013850415512\n",
      "Epoch 143, Train Accuracy: 0.6101666666666666\n",
      "Epoch 143, Dev Accuracy: 0.5795013850415512\n",
      "Epoch 144, Train Accuracy: 0.61\n",
      "Epoch 144, Dev Accuracy: 0.5795013850415512\n",
      "Epoch 145, Train Accuracy: 0.6096666666666667\n",
      "Epoch 145, Dev Accuracy: 0.5796398891966759\n",
      "Epoch 146, Train Accuracy: 0.6096666666666667\n",
      "Epoch 146, Dev Accuracy: 0.5796398891966759\n",
      "Epoch 147, Train Accuracy: 0.61\n",
      "Epoch 147, Dev Accuracy: 0.5799168975069252\n",
      "Epoch 148, Train Accuracy: 0.61\n",
      "Epoch 148, Dev Accuracy: 0.5796398891966759\n",
      "Epoch 149, Train Accuracy: 0.6103333333333333\n",
      "Epoch 149, Dev Accuracy: 0.5795013850415512\n",
      "Epoch 150, Train Accuracy: 0.6101666666666666\n",
      "Epoch 150, Dev Accuracy: 0.5793628808864266\n",
      "Epoch 151, Train Accuracy: 0.6103333333333333\n",
      "Epoch 151, Dev Accuracy: 0.5788088642659279\n",
      "Epoch 152, Train Accuracy: 0.6106666666666667\n",
      "Epoch 152, Dev Accuracy: 0.5788088642659279\n",
      "Epoch 153, Train Accuracy: 0.61\n",
      "Epoch 153, Dev Accuracy: 0.5789473684210527\n",
      "Epoch 154, Train Accuracy: 0.6101666666666666\n",
      "Epoch 154, Dev Accuracy: 0.5786703601108033\n",
      "Epoch 155, Train Accuracy: 0.6101666666666666\n",
      "Epoch 155, Dev Accuracy: 0.5785318559556787\n",
      "Epoch 156, Train Accuracy: 0.61\n",
      "Epoch 156, Dev Accuracy: 0.5785318559556787\n",
      "Epoch 157, Train Accuracy: 0.6105\n",
      "Epoch 157, Dev Accuracy: 0.5781163434903047\n",
      "Epoch 158, Train Accuracy: 0.6103333333333333\n",
      "Epoch 158, Dev Accuracy: 0.5778393351800554\n",
      "Epoch 159, Train Accuracy: 0.6103333333333333\n",
      "Epoch 159, Dev Accuracy: 0.5779778393351801\n",
      "Epoch 160, Train Accuracy: 0.6103333333333333\n",
      "Epoch 160, Dev Accuracy: 0.5775623268698061\n",
      "Epoch 161, Train Accuracy: 0.6103333333333333\n",
      "Epoch 161, Dev Accuracy: 0.5777008310249307\n",
      "Epoch 162, Train Accuracy: 0.6105\n",
      "Epoch 162, Dev Accuracy: 0.5778393351800554\n",
      "Epoch 163, Train Accuracy: 0.6103333333333333\n",
      "Epoch 163, Dev Accuracy: 0.5777008310249307\n",
      "Epoch 164, Train Accuracy: 0.6103333333333333\n",
      "Epoch 164, Dev Accuracy: 0.5777008310249307\n",
      "Epoch 165, Train Accuracy: 0.6098333333333333\n",
      "Epoch 165, Dev Accuracy: 0.5774238227146814\n",
      "Epoch 166, Train Accuracy: 0.61\n",
      "Epoch 166, Dev Accuracy: 0.5774238227146814\n",
      "Epoch 167, Train Accuracy: 0.6101666666666666\n",
      "Epoch 167, Dev Accuracy: 0.5777008310249307\n",
      "Epoch 168, Train Accuracy: 0.61\n",
      "Epoch 168, Dev Accuracy: 0.5774238227146814\n",
      "Epoch 169, Train Accuracy: 0.6098333333333333\n",
      "Epoch 169, Dev Accuracy: 0.5768698060941828\n",
      "Epoch 170, Train Accuracy: 0.6101666666666666\n",
      "Epoch 170, Dev Accuracy: 0.5770083102493074\n",
      "Epoch 171, Train Accuracy: 0.6101666666666666\n",
      "Epoch 171, Dev Accuracy: 0.5770083102493074\n",
      "Epoch 172, Train Accuracy: 0.6098333333333333\n",
      "Epoch 172, Dev Accuracy: 0.5770083102493074\n",
      "Epoch 173, Train Accuracy: 0.6093333333333333\n",
      "Epoch 173, Dev Accuracy: 0.5770083102493074\n",
      "Epoch 174, Train Accuracy: 0.6096666666666667\n",
      "Epoch 174, Dev Accuracy: 0.5768698060941828\n",
      "Epoch 175, Train Accuracy: 0.6091666666666666\n",
      "Epoch 175, Dev Accuracy: 0.5771468144044322\n",
      "Epoch 176, Train Accuracy: 0.6093333333333333\n",
      "Epoch 176, Dev Accuracy: 0.5763157894736842\n",
      "Epoch 177, Train Accuracy: 0.6095\n",
      "Epoch 177, Dev Accuracy: 0.5764542936288088\n",
      "Epoch 178, Train Accuracy: 0.6095\n",
      "Epoch 178, Dev Accuracy: 0.5763157894736842\n",
      "Epoch 179, Train Accuracy: 0.6096666666666667\n",
      "Epoch 179, Dev Accuracy: 0.5760387811634349\n",
      "Epoch 180, Train Accuracy: 0.6095\n",
      "Epoch 180, Dev Accuracy: 0.5754847645429363\n",
      "Epoch 181, Train Accuracy: 0.6095\n",
      "Epoch 181, Dev Accuracy: 0.5759002770083103\n",
      "Epoch 182, Train Accuracy: 0.6093333333333333\n",
      "Epoch 182, Dev Accuracy: 0.5756232686980609\n",
      "Epoch 183, Train Accuracy: 0.6091666666666666\n",
      "Epoch 183, Dev Accuracy: 0.5750692520775623\n",
      "Epoch 184, Train Accuracy: 0.6093333333333333\n",
      "Epoch 184, Dev Accuracy: 0.5756232686980609\n",
      "Epoch 185, Train Accuracy: 0.6091666666666666\n",
      "Epoch 185, Dev Accuracy: 0.5752077562326869\n",
      "Epoch 186, Train Accuracy: 0.6091666666666666\n",
      "Epoch 186, Dev Accuracy: 0.5753462603878117\n",
      "Epoch 187, Train Accuracy: 0.6091666666666666\n",
      "Epoch 187, Dev Accuracy: 0.5752077562326869\n",
      "Epoch 188, Train Accuracy: 0.609\n",
      "Epoch 188, Dev Accuracy: 0.5750692520775623\n",
      "Epoch 189, Train Accuracy: 0.6088333333333333\n",
      "Epoch 189, Dev Accuracy: 0.574792243767313\n",
      "Epoch 190, Train Accuracy: 0.6091666666666666\n",
      "Epoch 190, Dev Accuracy: 0.5752077562326869\n",
      "Epoch 191, Train Accuracy: 0.6091666666666666\n",
      "Epoch 191, Dev Accuracy: 0.5746537396121884\n",
      "Epoch 192, Train Accuracy: 0.609\n",
      "Epoch 192, Dev Accuracy: 0.5746537396121884\n",
      "Epoch 193, Train Accuracy: 0.6091666666666666\n",
      "Epoch 193, Dev Accuracy: 0.5750692520775623\n",
      "Epoch 194, Train Accuracy: 0.6093333333333333\n",
      "Epoch 194, Dev Accuracy: 0.5749307479224377\n",
      "Epoch 195, Train Accuracy: 0.6093333333333333\n",
      "Epoch 195, Dev Accuracy: 0.5749307479224377\n",
      "Epoch 196, Train Accuracy: 0.6091666666666666\n",
      "Epoch 196, Dev Accuracy: 0.5749307479224377\n",
      "Epoch 197, Train Accuracy: 0.6088333333333333\n",
      "Epoch 197, Dev Accuracy: 0.5745152354570637\n",
      "Epoch 198, Train Accuracy: 0.6081666666666666\n",
      "Epoch 198, Dev Accuracy: 0.574376731301939\n",
      "Epoch 199, Train Accuracy: 0.6086666666666667\n",
      "Epoch 199, Dev Accuracy: 0.5746537396121884\n",
      "Epoch 200, Train Accuracy: 0.6086666666666667\n",
      "Epoch 200, Dev Accuracy: 0.574376731301939\n",
      "Train Accuracy: 0.6086666666666667\n",
      "Val Accuracy: 0.574376731301939\n"
     ]
    }
   ],
   "source": [
    "model = SoftmaxClassifier(input_dim, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=alpha)\n",
    "\n",
    "train_accuracies, dev_accuracies, loss_per_epoch = train_softmax(model, train_loader, dev_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracies[-1])\n",
    "print(\"Val Accuracy:\", dev_accuracies[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Softmax Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(AutoencoderClassifier, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, 192),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(192, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 192),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(192, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoding = self.encoder(x)\n",
    "        decoding = self.decoder(encoding)\n",
    "        classification = self.classifier(encoding)\n",
    "        return encoding, decoding, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, train_loader, dev_loader, criterion, optimizer, num_epochs=200):\n",
    "    model.train()\n",
    "\n",
    "    train_accuracies = []\n",
    "    dev_accuracies = []\n",
    "    loss_per_epoch = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        cost_list = []\n",
    "        correct_train = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            encoding, decoding, preds = model(inputs)\n",
    "            reconstruction_loss = criterion(decoding, inputs)\n",
    "            classification_loss = classification_weight * criterion(preds, labels.float())  # Convert labels to float\n",
    "            loss = reconstruction_loss + classification_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predictions = torch.max(preds, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            correct_train += torch.sum(predictions == labels).item()\n",
    "\n",
    "            cost_list.append(loss.item())\n",
    "\n",
    "        accuracy_train = correct_train / float(len(train_loader.dataset))\n",
    "        print(f\"Epoch {epoch + 1}, Train Accuracy: {accuracy_train}\")\n",
    "        loss_per_epoch = float(sum(cost_list)) / len(cost_list)\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {loss_per_epoch}\")\n",
    "\n",
    "        model.eval()\n",
    "        correct_dev = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dev_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                _, _, preds = model(inputs)\n",
    "\n",
    "                _, predictions = torch.max(preds, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                correct_dev += torch.sum(predictions == labels).item()\n",
    "\n",
    "        accuracy_dev = correct_dev / float(len(dev_loader.dataset))\n",
    "        print(f\"Test Accuracy: {accuracy_dev}\")\n",
    "\n",
    "        train_accuracies.append(accuracy_train)\n",
    "        dev_accuracies.append(accuracy_dev)\n",
    "    \n",
    "    return train_accuracies, dev_accuracies, loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 0.5455\n",
      "Epoch 1, Train Loss: 0.13333338809510073\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 2, Train Accuracy: 0.5981666666666666\n",
      "Epoch 2, Train Loss: 0.12473893538117409\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 3, Train Accuracy: 0.5981666666666666\n",
      "Epoch 3, Train Loss: 0.1167018786072731\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 4, Train Accuracy: 0.5981666666666666\n",
      "Epoch 4, Train Loss: 0.10676331507662933\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 5, Train Accuracy: 0.5981666666666666\n",
      "Epoch 5, Train Loss: 0.09464194563527902\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 6, Train Accuracy: 0.5981666666666666\n",
      "Epoch 6, Train Loss: 0.0835690548022588\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 7, Train Accuracy: 0.5981666666666666\n",
      "Epoch 7, Train Loss: 0.07096674044926961\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 8, Train Accuracy: 0.5981666666666666\n",
      "Epoch 8, Train Loss: 0.058926244266331196\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 9, Train Accuracy: 0.5981666666666666\n",
      "Epoch 9, Train Loss: 0.0458877415706714\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 10, Train Accuracy: 0.5981666666666666\n",
      "Epoch 10, Train Loss: 0.02918659709393978\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 11, Train Accuracy: 0.5981666666666666\n",
      "Epoch 11, Train Loss: 0.008853468423088392\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 12, Train Accuracy: 0.5981666666666666\n",
      "Epoch 12, Train Loss: -0.015836040178934734\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 13, Train Accuracy: 0.5981666666666666\n",
      "Epoch 13, Train Loss: -0.04536399245262146\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 14, Train Accuracy: 0.5981666666666666\n",
      "Epoch 14, Train Loss: -0.08036572982867558\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 15, Train Accuracy: 0.5981666666666666\n",
      "Epoch 15, Train Loss: -0.12390989375611146\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 16, Train Accuracy: 0.5981666666666666\n",
      "Epoch 16, Train Loss: -0.17440603797634444\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 17, Train Accuracy: 0.5981666666666666\n",
      "Epoch 17, Train Loss: -0.24592465783158937\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 18, Train Accuracy: 0.5981666666666666\n",
      "Epoch 18, Train Loss: -0.3200569873054822\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 19, Train Accuracy: 0.5981666666666666\n",
      "Epoch 19, Train Loss: -0.3909265287220478\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 20, Train Accuracy: 0.5981666666666666\n",
      "Epoch 20, Train Loss: -0.47965321441491443\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 21, Train Accuracy: 0.5981666666666666\n",
      "Epoch 21, Train Loss: -0.5962774232029915\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 22, Train Accuracy: 0.5981666666666666\n",
      "Epoch 22, Train Loss: -0.7132315213481585\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 23, Train Accuracy: 0.5981666666666666\n",
      "Epoch 23, Train Loss: -0.8104197060068449\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 24, Train Accuracy: 0.5981666666666666\n",
      "Epoch 24, Train Loss: -0.959195502102375\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 25, Train Accuracy: 0.5981666666666666\n",
      "Epoch 25, Train Loss: -1.1173386474450429\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 26, Train Accuracy: 0.5981666666666666\n",
      "Epoch 26, Train Loss: -1.2678893307844799\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 27, Train Accuracy: 0.5981666666666666\n",
      "Epoch 27, Train Loss: -1.4254891177018483\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 28, Train Accuracy: 0.5981666666666666\n",
      "Epoch 28, Train Loss: -1.6065356334050496\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 29, Train Accuracy: 0.5981666666666666\n",
      "Epoch 29, Train Loss: -1.7513014872868855\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 30, Train Accuracy: 0.5981666666666666\n",
      "Epoch 30, Train Loss: -1.9768664588530858\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 31, Train Accuracy: 0.5981666666666666\n",
      "Epoch 31, Train Loss: -2.149940629800161\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 32, Train Accuracy: 0.5981666666666666\n",
      "Epoch 32, Train Loss: -2.3609875241915383\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 33, Train Accuracy: 0.5981666666666666\n",
      "Epoch 33, Train Loss: -2.5665466586748757\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 34, Train Accuracy: 0.5981666666666666\n",
      "Epoch 34, Train Loss: -2.8098882138729095\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 35, Train Accuracy: 0.5981666666666666\n",
      "Epoch 35, Train Loss: -3.015246490637461\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 36, Train Accuracy: 0.5981666666666666\n",
      "Epoch 36, Train Loss: -3.311270366112391\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 37, Train Accuracy: 0.5981666666666666\n",
      "Epoch 37, Train Loss: -3.5089990297953286\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 38, Train Accuracy: 0.5981666666666666\n",
      "Epoch 38, Train Loss: -3.8102138936519623\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 39, Train Accuracy: 0.5981666666666666\n",
      "Epoch 39, Train Loss: -4.0500315725803375\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 40, Train Accuracy: 0.5981666666666666\n",
      "Epoch 40, Train Loss: -4.273226618766785\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 41, Train Accuracy: 0.5981666666666666\n",
      "Epoch 41, Train Loss: -4.563278178373973\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 42, Train Accuracy: 0.5981666666666666\n",
      "Epoch 42, Train Loss: -4.93314387400945\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 43, Train Accuracy: 0.5981666666666666\n",
      "Epoch 43, Train Loss: -5.210176944732666\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 44, Train Accuracy: 0.5981666666666666\n",
      "Epoch 44, Train Loss: -5.341111226628224\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 45, Train Accuracy: 0.5981666666666666\n",
      "Epoch 45, Train Loss: -5.725366512934367\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 46, Train Accuracy: 0.5981666666666666\n",
      "Epoch 46, Train Loss: -6.03290182352066\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 47, Train Accuracy: 0.5981666666666666\n",
      "Epoch 47, Train Loss: -6.383450627326965\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 48, Train Accuracy: 0.5981666666666666\n",
      "Epoch 48, Train Loss: -6.765050272146861\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 49, Train Accuracy: 0.5981666666666666\n",
      "Epoch 49, Train Loss: -7.03622043132782\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 50, Train Accuracy: 0.5981666666666666\n",
      "Epoch 50, Train Loss: -7.295718431472778\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 51, Train Accuracy: 0.5981666666666666\n",
      "Epoch 51, Train Loss: -7.819790442784627\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 52, Train Accuracy: 0.5981666666666666\n",
      "Epoch 52, Train Loss: -8.19807372490565\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 53, Train Accuracy: 0.5981666666666666\n",
      "Epoch 53, Train Loss: -8.491743326187134\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 54, Train Accuracy: 0.5981666666666666\n",
      "Epoch 54, Train Loss: -8.77833366394043\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 55, Train Accuracy: 0.5981666666666666\n",
      "Epoch 55, Train Loss: -9.223927477995554\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 56, Train Accuracy: 0.5981666666666666\n",
      "Epoch 56, Train Loss: -9.658703724543253\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 57, Train Accuracy: 0.5981666666666666\n",
      "Epoch 57, Train Loss: -10.095240791638693\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 58, Train Accuracy: 0.5981666666666666\n",
      "Epoch 58, Train Loss: -10.437934696674347\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 59, Train Accuracy: 0.5981666666666666\n",
      "Epoch 59, Train Loss: -10.92713987827301\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 60, Train Accuracy: 0.5981666666666666\n",
      "Epoch 60, Train Loss: -11.17967047293981\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 61, Train Accuracy: 0.5981666666666666\n",
      "Epoch 61, Train Loss: -11.65998125076294\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 62, Train Accuracy: 0.5981666666666666\n",
      "Epoch 62, Train Loss: -12.113564650217691\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 63, Train Accuracy: 0.5981666666666666\n",
      "Epoch 63, Train Loss: -12.56745465596517\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 64, Train Accuracy: 0.5981666666666666\n",
      "Epoch 64, Train Loss: -13.069384733835856\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 65, Train Accuracy: 0.5981666666666666\n",
      "Epoch 65, Train Loss: -13.550095160802206\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 66, Train Accuracy: 0.5981666666666666\n",
      "Epoch 66, Train Loss: -13.694450805584589\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 67, Train Accuracy: 0.5981666666666666\n",
      "Epoch 67, Train Loss: -14.346947034200033\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 68, Train Accuracy: 0.5981666666666666\n",
      "Epoch 68, Train Loss: -14.904627402623495\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 69, Train Accuracy: 0.5981666666666666\n",
      "Epoch 69, Train Loss: -15.727096875508627\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 70, Train Accuracy: 0.5981666666666666\n",
      "Epoch 70, Train Loss: -16.92190758387248\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 71, Train Accuracy: 0.5981666666666666\n",
      "Epoch 71, Train Loss: -20.19313581784566\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 72, Train Accuracy: 0.5981666666666666\n",
      "Epoch 72, Train Loss: -24.30131697654724\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 73, Train Accuracy: 0.5981666666666666\n",
      "Epoch 73, Train Loss: -27.56449095408122\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 74, Train Accuracy: 0.5981666666666666\n",
      "Epoch 74, Train Loss: -30.611308733622234\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 75, Train Accuracy: 0.5981666666666666\n",
      "Epoch 75, Train Loss: -33.27178160349528\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 76, Train Accuracy: 0.5981666666666666\n",
      "Epoch 76, Train Loss: -35.869085947672524\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 77, Train Accuracy: 0.5981666666666666\n",
      "Epoch 77, Train Loss: -38.529929637908936\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 78, Train Accuracy: 0.5981666666666666\n",
      "Epoch 78, Train Loss: -41.159155209859215\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 79, Train Accuracy: 0.5981666666666666\n",
      "Epoch 79, Train Loss: -43.88641230265299\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 80, Train Accuracy: 0.5981666666666666\n",
      "Epoch 80, Train Loss: -46.48649215698242\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 81, Train Accuracy: 0.5981666666666666\n",
      "Epoch 81, Train Loss: -48.79228909810384\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 82, Train Accuracy: 0.5981666666666666\n",
      "Epoch 82, Train Loss: -51.95191764831543\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 83, Train Accuracy: 0.5981666666666666\n",
      "Epoch 83, Train Loss: -54.777980168660484\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 84, Train Accuracy: 0.5981666666666666\n",
      "Epoch 84, Train Loss: -57.65446917215983\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 85, Train Accuracy: 0.5981666666666666\n",
      "Epoch 85, Train Loss: -60.4131867090861\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 86, Train Accuracy: 0.5981666666666666\n",
      "Epoch 86, Train Loss: -63.232890129089355\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 87, Train Accuracy: 0.5981666666666666\n",
      "Epoch 87, Train Loss: -65.97224458058675\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 88, Train Accuracy: 0.5981666666666666\n",
      "Epoch 88, Train Loss: -69.37869707743327\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 89, Train Accuracy: 0.5981666666666666\n",
      "Epoch 89, Train Loss: -72.15500831604004\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 90, Train Accuracy: 0.5981666666666666\n",
      "Epoch 90, Train Loss: -76.02646287282307\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 91, Train Accuracy: 0.5981666666666666\n",
      "Epoch 91, Train Loss: -78.8636843363444\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 92, Train Accuracy: 0.5981666666666666\n",
      "Epoch 92, Train Loss: -82.06058438618977\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 93, Train Accuracy: 0.5981666666666666\n",
      "Epoch 93, Train Loss: -85.31032752990723\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 94, Train Accuracy: 0.5981666666666666\n",
      "Epoch 94, Train Loss: -89.06058120727539\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 95, Train Accuracy: 0.5981666666666666\n",
      "Epoch 95, Train Loss: -92.59465090433757\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 96, Train Accuracy: 0.5981666666666666\n",
      "Epoch 96, Train Loss: -95.68853950500488\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 97, Train Accuracy: 0.5981666666666666\n",
      "Epoch 97, Train Loss: -98.96017964680989\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 98, Train Accuracy: 0.5981666666666666\n",
      "Epoch 98, Train Loss: -102.52767499287923\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 99, Train Accuracy: 0.5981666666666666\n",
      "Epoch 99, Train Loss: -106.4307238260905\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 100, Train Accuracy: 0.5981666666666666\n",
      "Epoch 100, Train Loss: -110.4501355489095\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 101, Train Accuracy: 0.5981666666666666\n",
      "Epoch 101, Train Loss: -113.95873514811198\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 102, Train Accuracy: 0.5981666666666666\n",
      "Epoch 102, Train Loss: -117.69503784179688\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 103, Train Accuracy: 0.5981666666666666\n",
      "Epoch 103, Train Loss: -121.3221549987793\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 104, Train Accuracy: 0.5981666666666666\n",
      "Epoch 104, Train Loss: -124.71968078613281\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 105, Train Accuracy: 0.5981666666666666\n",
      "Epoch 105, Train Loss: -129.72027715047201\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 106, Train Accuracy: 0.5981666666666666\n",
      "Epoch 106, Train Loss: -132.85674158732095\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 107, Train Accuracy: 0.5981666666666666\n",
      "Epoch 107, Train Loss: -137.20074907938638\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 108, Train Accuracy: 0.5981666666666666\n",
      "Epoch 108, Train Loss: -141.91566212972006\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 109, Train Accuracy: 0.5981666666666666\n",
      "Epoch 109, Train Loss: -145.76216570536295\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 110, Train Accuracy: 0.5981666666666666\n",
      "Epoch 110, Train Loss: -149.94482930501303\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 111, Train Accuracy: 0.5981666666666666\n",
      "Epoch 111, Train Loss: -154.86924107869467\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 112, Train Accuracy: 0.5981666666666666\n",
      "Epoch 112, Train Loss: -159.49932543436685\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 113, Train Accuracy: 0.5981666666666666\n",
      "Epoch 113, Train Loss: -163.15672175089517\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 114, Train Accuracy: 0.5981666666666666\n",
      "Epoch 114, Train Loss: -167.65818786621094\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 115, Train Accuracy: 0.5981666666666666\n",
      "Epoch 115, Train Loss: -172.03899383544922\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 116, Train Accuracy: 0.5981666666666666\n",
      "Epoch 116, Train Loss: -176.44775263468424\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 117, Train Accuracy: 0.5981666666666666\n",
      "Epoch 117, Train Loss: -180.33935038248697\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 118, Train Accuracy: 0.5981666666666666\n",
      "Epoch 118, Train Loss: -185.69784673055014\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 119, Train Accuracy: 0.5981666666666666\n",
      "Epoch 119, Train Loss: -189.8394521077474\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 120, Train Accuracy: 0.5981666666666666\n",
      "Epoch 120, Train Loss: -193.72198994954428\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 121, Train Accuracy: 0.5981666666666666\n",
      "Epoch 121, Train Loss: -200.10789489746094\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 122, Train Accuracy: 0.5981666666666666\n",
      "Epoch 122, Train Loss: -204.0585174560547\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 123, Train Accuracy: 0.5981666666666666\n",
      "Epoch 123, Train Loss: -208.22188568115234\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 124, Train Accuracy: 0.5981666666666666\n",
      "Epoch 124, Train Loss: -214.24667358398438\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 125, Train Accuracy: 0.5981666666666666\n",
      "Epoch 125, Train Loss: -219.22820663452148\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 126, Train Accuracy: 0.5981666666666666\n",
      "Epoch 126, Train Loss: -225.44562530517578\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 127, Train Accuracy: 0.5981666666666666\n",
      "Epoch 127, Train Loss: -229.9235585530599\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 128, Train Accuracy: 0.5981666666666666\n",
      "Epoch 128, Train Loss: -234.4099235534668\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 129, Train Accuracy: 0.5981666666666666\n",
      "Epoch 129, Train Loss: -239.5300610860189\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 130, Train Accuracy: 0.5981666666666666\n",
      "Epoch 130, Train Loss: -244.8550796508789\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 131, Train Accuracy: 0.5981666666666666\n",
      "Epoch 131, Train Loss: -251.5616683959961\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 132, Train Accuracy: 0.5981666666666666\n",
      "Epoch 132, Train Loss: -255.4549077351888\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 133, Train Accuracy: 0.5981666666666666\n",
      "Epoch 133, Train Loss: -259.8936703999837\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 134, Train Accuracy: 0.5981666666666666\n",
      "Epoch 134, Train Loss: -266.15295791625977\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 135, Train Accuracy: 0.5981666666666666\n",
      "Epoch 135, Train Loss: -270.8672688802083\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 136, Train Accuracy: 0.5981666666666666\n",
      "Epoch 136, Train Loss: -277.3604164123535\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 137, Train Accuracy: 0.5981666666666666\n",
      "Epoch 137, Train Loss: -283.04175186157227\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 138, Train Accuracy: 0.5981666666666666\n",
      "Epoch 138, Train Loss: -288.94365946451825\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 139, Train Accuracy: 0.5981666666666666\n",
      "Epoch 139, Train Loss: -293.3707567850749\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 140, Train Accuracy: 0.5981666666666666\n",
      "Epoch 140, Train Loss: -298.86263275146484\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 141, Train Accuracy: 0.5981666666666666\n",
      "Epoch 141, Train Loss: -304.7750193277995\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 142, Train Accuracy: 0.5981666666666666\n",
      "Epoch 142, Train Loss: -310.847900390625\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 143, Train Accuracy: 0.5981666666666666\n",
      "Epoch 143, Train Loss: -316.7771352132161\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 144, Train Accuracy: 0.5981666666666666\n",
      "Epoch 144, Train Loss: -321.266606648763\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 145, Train Accuracy: 0.5981666666666666\n",
      "Epoch 145, Train Loss: -328.0486526489258\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 146, Train Accuracy: 0.5981666666666666\n",
      "Epoch 146, Train Loss: -334.7407684326172\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 147, Train Accuracy: 0.5981666666666666\n",
      "Epoch 147, Train Loss: -339.6400947570801\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 148, Train Accuracy: 0.5981666666666666\n",
      "Epoch 148, Train Loss: -346.4091288248698\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 149, Train Accuracy: 0.5981666666666666\n",
      "Epoch 149, Train Loss: -350.5087610880534\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 150, Train Accuracy: 0.5981666666666666\n",
      "Epoch 150, Train Loss: -356.575688680013\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 151, Train Accuracy: 0.5981666666666666\n",
      "Epoch 151, Train Loss: -363.63300069173175\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 152, Train Accuracy: 0.5981666666666666\n",
      "Epoch 152, Train Loss: -370.47365315755206\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 153, Train Accuracy: 0.5981666666666666\n",
      "Epoch 153, Train Loss: -374.10689544677734\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 154, Train Accuracy: 0.5981666666666666\n",
      "Epoch 154, Train Loss: -383.88795216878253\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 155, Train Accuracy: 0.5981666666666666\n",
      "Epoch 155, Train Loss: -387.782475789388\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 156, Train Accuracy: 0.5981666666666666\n",
      "Epoch 156, Train Loss: -396.2569758097331\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 157, Train Accuracy: 0.5981666666666666\n",
      "Epoch 157, Train Loss: -399.9700876871745\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 158, Train Accuracy: 0.5981666666666666\n",
      "Epoch 158, Train Loss: -403.8976236979167\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 159, Train Accuracy: 0.5981666666666666\n",
      "Epoch 159, Train Loss: -413.483154296875\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 160, Train Accuracy: 0.5981666666666666\n",
      "Epoch 160, Train Loss: -422.00438435872394\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 161, Train Accuracy: 0.5981666666666666\n",
      "Epoch 161, Train Loss: -428.2347895304362\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 162, Train Accuracy: 0.5981666666666666\n",
      "Epoch 162, Train Loss: -433.8597640991211\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 163, Train Accuracy: 0.5981666666666666\n",
      "Epoch 163, Train Loss: -437.3063659667969\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 164, Train Accuracy: 0.5981666666666666\n",
      "Epoch 164, Train Loss: -445.63938395182294\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 165, Train Accuracy: 0.5981666666666666\n",
      "Epoch 165, Train Loss: -452.93157958984375\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 166, Train Accuracy: 0.5981666666666666\n",
      "Epoch 166, Train Loss: -460.5522282918294\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 167, Train Accuracy: 0.5981666666666666\n",
      "Epoch 167, Train Loss: -468.35552978515625\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 168, Train Accuracy: 0.5981666666666666\n",
      "Epoch 168, Train Loss: -472.17449442545575\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 169, Train Accuracy: 0.5981666666666666\n",
      "Epoch 169, Train Loss: -480.5960184733073\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 170, Train Accuracy: 0.5981666666666666\n",
      "Epoch 170, Train Loss: -486.5152409871419\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 171, Train Accuracy: 0.5981666666666666\n",
      "Epoch 171, Train Loss: -491.6571222941081\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 172, Train Accuracy: 0.5981666666666666\n",
      "Epoch 172, Train Loss: -499.02585856119794\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 173, Train Accuracy: 0.5981666666666666\n",
      "Epoch 173, Train Loss: -505.41602579752606\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 174, Train Accuracy: 0.5981666666666666\n",
      "Epoch 174, Train Loss: -515.2477315266927\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 175, Train Accuracy: 0.5981666666666666\n",
      "Epoch 175, Train Loss: -522.5405909220377\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 176, Train Accuracy: 0.5981666666666666\n",
      "Epoch 176, Train Loss: -527.7161026000977\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 177, Train Accuracy: 0.5981666666666666\n",
      "Epoch 177, Train Loss: -538.0701243082682\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 178, Train Accuracy: 0.5981666666666666\n",
      "Epoch 178, Train Loss: -543.2829462687174\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 179, Train Accuracy: 0.5981666666666666\n",
      "Epoch 179, Train Loss: -549.4405873616537\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 180, Train Accuracy: 0.5981666666666666\n",
      "Epoch 180, Train Loss: -557.9469477335612\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 181, Train Accuracy: 0.5981666666666666\n",
      "Epoch 181, Train Loss: -564.0935974121094\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 182, Train Accuracy: 0.5981666666666666\n",
      "Epoch 182, Train Loss: -572.0158996582031\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 183, Train Accuracy: 0.5981666666666666\n",
      "Epoch 183, Train Loss: -580.3516693115234\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 184, Train Accuracy: 0.5981666666666666\n",
      "Epoch 184, Train Loss: -585.7318598429362\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 185, Train Accuracy: 0.5981666666666666\n",
      "Epoch 185, Train Loss: -593.4013722737631\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 186, Train Accuracy: 0.5981666666666666\n",
      "Epoch 186, Train Loss: -601.673095703125\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 187, Train Accuracy: 0.5981666666666666\n",
      "Epoch 187, Train Loss: -608.0337066650391\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 188, Train Accuracy: 0.5981666666666666\n",
      "Epoch 188, Train Loss: -617.4197133382162\n",
      "Test Accuracy: 0.5915512465373961\n",
      "Epoch 189, Train Accuracy: 0.6031666666666666\n",
      "Epoch 189, Train Loss: -622.6327997843424\n",
      "Test Accuracy: 0.586426592797784\n",
      "Epoch 190, Train Accuracy: 0.6156666666666667\n",
      "Epoch 190, Train Loss: -633.7852884928385\n",
      "Test Accuracy: 0.6626038781163435\n",
      "Epoch 191, Train Accuracy: 0.6781666666666667\n",
      "Epoch 191, Train Loss: -636.0625203450521\n",
      "Test Accuracy: 0.6660664819944598\n",
      "Epoch 192, Train Accuracy: 0.6673333333333333\n",
      "Epoch 192, Train Loss: -643.7978871663412\n",
      "Test Accuracy: 0.5808864265927978\n",
      "Epoch 193, Train Accuracy: 0.6396666666666667\n",
      "Epoch 193, Train Loss: -654.2463175455729\n",
      "Test Accuracy: 0.6645429362880887\n",
      "Epoch 194, Train Accuracy: 0.6556666666666666\n",
      "Epoch 194, Train Loss: -663.9495391845703\n",
      "Test Accuracy: 0.6631578947368421\n",
      "Epoch 195, Train Accuracy: 0.6541666666666667\n",
      "Epoch 195, Train Loss: -670.2095286051432\n",
      "Test Accuracy: 0.6555401662049861\n",
      "Epoch 196, Train Accuracy: 0.6478333333333334\n",
      "Epoch 196, Train Loss: -674.9902648925781\n",
      "Test Accuracy: 0.656786703601108\n",
      "Epoch 197, Train Accuracy: 0.6598333333333334\n",
      "Epoch 197, Train Loss: -685.4738413492838\n",
      "Test Accuracy: 0.6545706371191136\n",
      "Epoch 198, Train Accuracy: 0.666\n",
      "Epoch 198, Train Loss: -693.2143096923828\n",
      "Test Accuracy: 0.6533240997229917\n",
      "Epoch 199, Train Accuracy: 0.6681666666666667\n",
      "Epoch 199, Train Loss: -700.1677551269531\n",
      "Test Accuracy: 0.6558171745152355\n",
      "Epoch 200, Train Accuracy: 0.6688333333333333\n",
      "Epoch 200, Train Loss: -710.5231679280599\n",
      "Test Accuracy: 0.6558171745152355\n",
      "Train Accuracy: 0.6688333333333333\n",
      "Val Accuracy: 0.6558171745152355\n"
     ]
    }
   ],
   "source": [
    "model = AutoencoderClassifier(input_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=alpha)\n",
    "\n",
    "train_accuracies, dev_accuracies, loss_per_epoch = train_autoencoder(model, train_loader, dev_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracies[-1])\n",
    "print(\"Val Accuracy:\", dev_accuracies[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
